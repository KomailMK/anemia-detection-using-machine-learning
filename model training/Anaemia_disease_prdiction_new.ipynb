{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLziOLjmaKaD"
      },
      "source": [
        "# Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W5bY3SgaH2B"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 1: LIBRARY IMPORTS\n",
        "# ==========================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# import numpy as np  # Remove this redundant import\n",
        "# np.bool = bool  # Create alias for bool -> Remove or comment out this line\n",
        "import seaborn as sns\n",
        "\n",
        "# Sklearn modules\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ML models\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "# from catboost import CatBoostClassifier\n",
        "\n",
        "# Deep Learning modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, GRU, Conv1D, MaxPooling1D, Flatten, Dropout\n",
        "\n",
        "# For explainability (SHAP)\n",
        "#import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "MukZhUm2aShM",
        "outputId": "05412280-80ce-409d-e153-81f0b96708e9"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 2: LOAD DATA\n",
        "# ==========================\n",
        "# Example: If your dataset is a CSV file\n",
        "df=pd.read_excel('Anemia Dataset.xlsx')\n",
        "\n",
        "# For demonstration, we assume 'df' is already loaded with columns:\n",
        "# ['Gender', 'Age', 'Hb', 'RBC', 'PCV', 'MCV', 'MCH', 'MCHC', 'Decision_Class']\n",
        "\n",
        "print(\"Data Sample:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\nData Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "id": "q92jUV3xaH5V",
        "outputId": "34084ea1-571f-46db-ba94-92c8541d715a"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 3: EXPLORATORY DATA ANALYSIS\n",
        "# ==========================\n",
        "# Basic distribution of each feature\n",
        "df.hist(figsize=(12,8))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check class distribution\n",
        "print(\"Class Distribution:\")\n",
        "print(df['Decision_Class'].value_counts())\n",
        "\n",
        "# Boxplots to see outliers\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16,8))\n",
        "axes = axes.flatten()\n",
        "numeric_cols = ['Age', 'Hb', 'RBC', 'PCV', 'MCV', 'MCH', 'MCHC']\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    sns.boxplot(x=df[col], ax=axes[i])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdrS5NzIaka8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "vWTmH53Vakjf",
        "outputId": "cbe09dee-096e-4a90-a41e-ad880fed5c25"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 4: MISSING VALUE & OUTLIER HANDLING\n",
        "# ==========================\n",
        "\n",
        "# 1) Convert 'Gender' to numeric if needed\n",
        "df['Gender'] = df['Gender'].map({'m':1, 'f':0})  # or LabelEncoder\n",
        "\n",
        "# 2) Handle missing values with SimpleImputer (mean strategy)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "numeric_cols = ['Age', 'Hb', 'RBC', 'PCV', 'MCV', 'MCH', 'MCHC']\n",
        "\n",
        "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
        "\n",
        "# 3) (Optional) Outlier handling\n",
        "#    Example: remove rows beyond 3*IQR, or just clip them\n",
        "#    Here we simply show how to clip:\n",
        "for col in numeric_cols:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    df[col] = np.clip(df[col], lower_bound, upper_bound)\n",
        "\n",
        "print(\"Data after missing value & outlier handling:\")\n",
        "display(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-R29AKYaomV",
        "outputId": "b94a6327-25b2-473e-b48a-49bf873d3bd3"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 5: FEATURE/TARGET SPLIT\n",
        "# ==========================\n",
        "X = df.drop('Decision_Class', axis=1)\n",
        "y = df['Decision_Class'].values  # 0 or 1\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6q393THarDM",
        "outputId": "baba9622-c7f3-4ec4-8932-ae2509f78006"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 6: TRAIN-TEST SPLIT\n",
        "# ==========================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train set:\", X_train.shape, y_train.shape)\n",
        "print(\"Test set:\", X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41gt3Qr6ar1P",
        "outputId": "91b416c7-0dec-4bf2-88b0-12cf4a934576"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 7: SMOTE FOR IMBALANCE\n",
        "# ==========================\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"After SMOTE, train shape:\", X_train_sm.shape, y_train_sm.shape)\n",
        "print(\"Class Distribution in y_train_sm:\", pd.Series(y_train_sm).value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7evifUPavFI"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 8: SCALING\n",
        "# ==========================\n",
        "scaler = StandardScaler()  # or MinMaxScaler\n",
        "X_train_sm_scaled = scaler.fit_transform(X_train_sm)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlyjAEnRavwf",
        "outputId": "dcbbcd83-02c5-494c-c99d-ccd50bc9b3b0"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 9: CLASSICAL ML MODELS\n",
        "# ==========================\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "models = {\n",
        "    \"SVM\": SVC(probability=True, random_state=42),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(random_state=42),\n",
        "    # \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    # Cross-validation on the training set\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    cv_scores = cross_val_score(model, X_train_sm_scaled, y_train_sm, cv=cv, scoring='accuracy')\n",
        "\n",
        "    # Train on the full training set\n",
        "    model.fit(X_train_sm_scaled, y_train_sm)\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Evaluate\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cls_report = classification_report(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"CV Accuracy (mean): {cv_scores.mean():.4f} | CV Std: {cv_scores.std():.4f}\")\n",
        "    print(f\"Test Accuracy: {acc:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", cls_report)\n",
        "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Store in results dict if needed\n",
        "    results[model_name] = {\n",
        "        \"cv_mean_acc\": cv_scores.mean(),\n",
        "        \"test_acc\": acc,\n",
        "        \"classification_report\": cls_report,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DN8kx0_ayfS",
        "outputId": "83ad9b03-5f18-49a0-9ceb-a20688290f40"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 10: HYPERPARAMETER TUNING EXAMPLE (RANDOM FOREST)\n",
        "# ==========================\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_sm_scaled, y_train_sm)\n",
        "print(\"Best Params:\", grid_search.best_params_)\n",
        "print(\"Best CV Score:\", grid_search.best_score_)\n",
        "\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred_rf = best_rf.predict(X_test_scaled)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "cls_report_rf = classification_report(y_test, y_pred_rf)\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"\\nTest Accuracy with Best RF: {acc_rf:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", cls_report_rf)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-8z_c8ra3gj",
        "outputId": "2ff1e690-1e83-483e-f3e5-d0306c9169f4"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 11: RESHAPE DATA FOR DEEP LEARNING\n",
        "# ==========================\n",
        "# Convert from (samples, features) -> (samples, timesteps=1, features)\n",
        "X_train_dl = np.expand_dims(X_train_sm_scaled, axis=1)\n",
        "X_test_dl = np.expand_dims(X_test_scaled, axis=1)\n",
        "\n",
        "print(\"New DL shape, X_train:\", X_train_dl.shape)  # (num_samples, 1, num_features)\n",
        "print(\"New DL shape, X_test:\", X_test_dl.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVTbSNgCa6Wm"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 12: DEFINE DL MODELS\n",
        "# ==========================\n",
        "\n",
        "def build_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, activation='relu', input_shape=input_shape))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_bilstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(64, activation='relu'), input_shape=input_shape))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_gru_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(GRU(64, activation='relu', input_shape=input_shape))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn_lstm_model(input_shape):\n",
        "    # For CNN, we need timesteps > 1 for a real convolution. We'll do a trivial example with kernel_size=1.\n",
        "    # This is just a demonstration.\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling1D(pool_size=1))\n",
        "    model.add(LSTM(64, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FItRC1aWa8pt",
        "outputId": "1a3fbb5a-58f8-439b-b4ca-5a475534c51a"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 13: TRAIN & EVALUATE DL MODELS\n",
        "# ==========================\n",
        "dl_models = {\n",
        "    \"LSTM\": build_lstm_model(X_train_dl.shape[1:]),\n",
        "    \"BiLSTM\": build_bilstm_model(X_train_dl.shape[1:]),\n",
        "    \"GRU\": build_gru_model(X_train_dl.shape[1:]),\n",
        "    \"CNN_LSTM\": build_cnn_lstm_model(X_train_dl.shape[1:])\n",
        "}\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "for name, dl_model in dl_models.items():\n",
        "    print(f\"\\nTraining {name} model...\")\n",
        "    history = dl_model.fit(\n",
        "        X_train_dl, y_train_sm,\n",
        "        validation_split=0.2,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        verbose=0  # set to 1 or 2 if you want to see the training progress\n",
        "    )\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred_prob = dl_model.predict(X_test_dl)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "    # Evaluate\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cls_report = classification_report(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Deep Learning Model: {name}\")\n",
        "    print(f\"Test Accuracy: {acc:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", cls_report)\n",
        "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "    print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "uTjh2nZDa_ni",
        "outputId": "3cb22ba5-d005-4061-d9df-45df0b16a0d3"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CELL 14: SHAP EXPLAINABILITY\n",
        "# ==========================\n",
        "# Example with XGBoost\n",
        "best_xgb = XGBClassifier(random_state=42)\n",
        "best_xgb.fit(X_train_sm_scaled, y_train_sm)\n",
        "\n",
        "explainer = shap.Explainer(best_xgb, X_train_sm_scaled)\n",
        "shap_values = explainer(X_test_scaled)\n",
        "\n",
        "# Summary plot\n",
        "shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLUJYVXO2vpC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XM35lKpM2vsY",
        "outputId": "f74a9614-1877-468a-e09a-76006391bbe8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Aapke model ke results yahaan daalen.\n",
        "# Main example ke liye kuch data use kar raha hoon.\n",
        "model_names = ['SVM', 'Decision Tree', 'Logistic Regression', 'Random Forest', 'XGBoost']\n",
        "accuracy = [0.95, 0.92, 0.90, 0.96, 0.97]\n",
        "f1_score = [0.94, 0.91, 0.89, 0.95, 0.96]\n",
        "recall = [0.93, 0.90, 0.88, 0.94, 0.95]\n",
        "precision = [0.95, 0.92, 0.90, 0.96, 0.97] # Precision values added\n",
        "\n",
        "# Dataframe banaen\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': model_names,\n",
        "    'Accuracy': accuracy,\n",
        "    'F1 Score': f1_score,\n",
        "    'Recall': recall,\n",
        "    'Precision': precision  # Precision column added\n",
        "})\n",
        "\n",
        "# Bar chart ke liye metrics\n",
        "metrics = ['Accuracy', 'F1 Score', 'Recall', 'Precision']\n",
        "\n",
        "# Har metric ke liye bar chart banaen\n",
        "for metric in metrics:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(results_df['Model'], results_df[metric])\n",
        "    plt.title(f'Model {metric} Comparison')\n",
        "    plt.xlabel('Model')\n",
        "    plt.ylabel(metric)\n",
        "    plt.ylim(0, 1)  # Y-axis ko 0 se 1 tak limit karein\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xUUpYhAj2vvn",
        "outputId": "2923abec-3ac2-4344-8cde-4741644fc101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as best_xgboost_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained best XGBoost model to a file\n",
        "joblib.dump(models[\"XGBoost\"], \"best_xgboost_model.pkl\")\n",
        "print(\"Model saved as best_xgboost_model.pkl\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
